{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ce6b1dc-be57-4247-a04f-3344b4f0ca97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "os.environ['HADOOP_CONF_DIR'] = '/etc/hadoop/conf'\n",
    "os.environ['YARN_CONF_DIR'] = '/etc/hadoop/conf'\n",
    "os.environ['PYSPARK_PYTHON'] =  'python3.9'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = 'python3.9'\n",
    "os.environ['HADOOP_USER_NAME']='ssenigov'\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf, StorageLevel, RDD\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db7c2edf-43ce-4a2e-ac39-be7a1964b3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/25 21:15:53 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/08/25 21:15:53 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "24/08/25 21:15:53 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "24/08/25 21:15:53 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "24/08/25 21:15:53 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n",
      "24/08/25 21:15:53 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    }
   ],
   "source": [
    "conf = SparkConf().setAppName('EnumRDDs')\\\n",
    "    .setMaster('yarn')\n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "241553a0-89d1-4c52-8440-1476e2cbed15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+\n",
      "|name|name2|age|\n",
      "+----+-----+---+\n",
      "|Mary|  Foo| 12|\n",
      "| Bob|  Bar| 14|\n",
      "+----+-----+---+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([('Mary', 'Foo', 12), ('Bob', 'Bar', 14)], ['name', 'name2', 'age'])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e4dcbad9-3b19-4d8d-a196-621fe0524032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head(None): type: <class 'NoneType'>, value: None)\n",
      "head(0): type: <class 'list'>, value: [])\n",
      "head(1): type: <class 'list'>, value: [])\n",
      "\n",
      "\n",
      "head(None): type: <class 'pyspark.sql.types.Row'>, value: Row(name='Mary', name2='Foo', age=12))\n",
      "head(0): type: <class 'list'>, value: [])\n",
      "head(1): type: <class 'list'>, value: [Row(name='Mary', name2='Foo', age=12)])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "for key in [False, True]:\n",
    "        \n",
    "    for n in [None, 0,1]:\n",
    "        # take_result = df.take(n)\n",
    "        # print('take({0}): type: {1}, value: {2})'.format(n, type(take_result), \\\n",
    "        #     take_result))\n",
    "    \n",
    "        head_result = df.where(lit(key)).head(n)\n",
    "        print('head({0}): type: {1}, value: {2})'.format(n, type(head_result), \\\n",
    "            head_result))\n",
    "    print('\\n')\n",
    "\n",
    "# n=1\n",
    "# take_0_result = df.take(n)\n",
    "# print('take({0}) result:\\n type: {1}\\n value: {2})'.format(n, type(take_0_result), \\\n",
    "#     take_0_result))\n",
    "\n",
    "# print(type(df.head()))\n",
    "# df.where('False').take(1)\n",
    "# df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b7e14f6-0819-4709-bbf4-18eab6d7198b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+----+---+----+---+----+---+----+---+----+---+----+---+----+---+----+-----+\n",
      "|name|age|name|age|name|age|name|age|name|age|name|age|name|age|name|age|name|name2|\n",
      "+----+---+----+---+----+---+----+---+----+---+----+---+----+---+----+---+----+-----+\n",
      "|Mary| 12|Mary| 12|Mary| 12|Mary| 12|Mary| 12|Mary| 12|Mary| 12|Mary| 12|Mary|  Foo|\n",
      "| Bob| 14| Bob| 14| Bob| 14| Bob| 14| Bob| 14| Bob| 14| Bob| 14| Bob| 14| Bob|  Bar|\n",
      "+----+---+----+---+----+---+----+---+----+---+----+---+----+---+----+---+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select([ \n",
    "    'name', 'age',             # by string\n",
    "    df.name, df.age,           # by method\n",
    "    col('name'), col('age'),   # with function col: from pyspark.sql.functions import col \n",
    "    df[0], df[2],              # by index of default collection \n",
    "    df.columns[0], df.columns[2], # explicitly by index of collection columns\n",
    "    df.__getattr__('name'), df.__getattr__('age'), # with __getattr__\n",
    "    df.__getitem__(0), df.__getitem__(2),          # with __getitem__\n",
    "    *([c for c in df.columns if c in ('age', 'name')]),  # build list from columns with condition\n",
    "    df.colRegex(\"`(age)?+.+`\") # by colRegex\n",
    " ]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9110d5b9-4ce3-494c-98c2-a5b540ad0245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|age|count|\n",
      "+---+-----+\n",
      "| 14|    1|\n",
      "| 12|    1|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy([df.age]).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8db69a7e-917e-4bdd-a5b9-026487e44195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----+\n",
      "|age| name|count|\n",
      "+---+-----+-----+\n",
      "| 14|  Bob|    1|\n",
      "| 12|Alice|    1|\n",
      "+---+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy([df.age, df.name]).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "25314af1-5674-420b-9fa7-612aa7dd2bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|age|count|\n",
      "+---+-----+\n",
      "| 14|    1|\n",
      "| 12|    1|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy([col(\"age\")]).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e22ae2c7-5950-49fe-b467-53a03e74a915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----+\n",
      "|age| name|count|\n",
      "+---+-----+-----+\n",
      "| 12|Alice|    1|\n",
      "| 14|  Bob|    1|\n",
      "+---+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy([col(\"age\"), col(\"name\")]).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25cae25b-2b71-4021-8f92-c6c4c205a06e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|age| name|\n",
      "+---+-----+\n",
      "| 12|Alice|\n",
      "| 14|  Bob|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df[[df.columns[1],df.columns[0]]].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac96b5ac-fdc0-4a1c-b52b-59e14e3f0285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|age|\n",
      "+---+\n",
      "| 12|\n",
      "| 14|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df[[df.__getattr__(\"age\")]].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6299f9e-491e-4caa-8714-437213055e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|age|\n",
      "+---+\n",
      "| 12|\n",
      "| 14|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df[[df.__getitem__(1)]].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "beb9f89c-057e-4084-aa59-4993551b770e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|age| name|\n",
      "+---+-----+\n",
      "| 12|Alice|\n",
      "| 14|  Bob|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"age\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "267935ac-7fac-4832-9c67-4250a2d3a2fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|age| name|\n",
      "+---+-----+\n",
      "| 12|Alice|\n",
      "| 14|  Bob|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"age\", \"name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ce6854c-c71a-4d68-9980-e9b419cfd470",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|age|\n",
      "+---+\n",
      "| 12|\n",
      "| 14|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.age).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "711cb9ec-3ce2-4f29-a36c-868db2619ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|age| name|\n",
      "+---+-----+\n",
      "| 12|Alice|\n",
      "| 14|  Bob|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.age, df.name).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ea465a0-6dba-470f-896f-4e33c09a1c5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|age| name|\n",
      "+---+-----+\n",
      "| 12|Alice|\n",
      "| 14|  Bob|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"v_children\")\n",
    "spark.sql(\"select age, name from v_children\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e244ed93-1a7d-452c-b8c2-b255d6656af3",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37dc8a7-69ab-4b0d-a751-c272f59b8681",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
