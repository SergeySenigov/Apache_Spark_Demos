{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce6b1dc-be57-4247-a04f-3344b4f0ca97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "os.environ['HADOOP_CONF_DIR'] = '/etc/hadoop/conf'\n",
    "os.environ['YARN_CONF_DIR'] = '/etc/hadoop/conf'\n",
    "os.environ['PYSPARK_PYTHON'] =  'python3.9'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = 'python3.9'\n",
    "os.environ['HADOOP_USER_NAME']='ssenigov'\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf, StorageLevel, RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7c2edf-43ce-4a2e-ac39-be7a1964b3e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conf = SparkConf().setAppName('Persist_With_Name')\\\n",
    "    .setMaster('yarn') \\\n",
    "    .set(\"spark.eventLog.logBlockUpdates.enabled\", 'true')\n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241553a0-89d1-4c52-8440-1476e2cbed15",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_1 = spark.sparkContext.parallelize(range(100), 5).cache().setName('I am RDD number 1')\n",
    "rdd_1.count()\n",
    "\n",
    "rdd_2 = spark.sparkContext.parallelize(range(100), 10).cache().setName('I am RDD number 2')\n",
    "rdd_2.count()\n",
    "\n",
    "rdd_3 = spark.sparkContext.parallelize(range(100), 15).cache()\n",
    "rdd_3 = rdd_3.count()\n",
    "\n",
    "rdd_4 = spark.sparkContext.parallelize(range(100), 20).cache()\n",
    "rdd_4 = rdd_4.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e158612d-c4ef-4e94-86fa-99c681368af8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3601d8ef-b65f-4e0e-9470-47051a507824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # rdd_customers_persisted_to_disk.unpersist()\n",
    "# rdd_numbers_persisted = rdd_numbers.cache()\n",
    "# # rdd_numbers.persist(StorageLevel.DISK_ONLY)\n",
    "# rdd_numbers_persisted.setName('I am persisted RDD')\n",
    "# rdd_numbers_persisted.count() # run action to materialise rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c142d8-ef27-404f-98ac-f24aba5aa90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(rdd_numbers_persisted.is_cached)\n",
    "\n",
    "# # if rdd_numbers_persisted_to_disk.is_cached:\n",
    "# #     rdd_numbers_persisted_to_disk.unpersist()\n",
    "# # print(rdd_numbers_persisted.is_cached)\n",
    "# # print(df_customers.is_cached)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baec9e6-e822-495c-8078-89276f24b27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_rdds():\n",
    "    return [k for (k, v) in globals().items() if isinstance(v, RDD)]\n",
    "\n",
    "set_rdds = set()\n",
    "\n",
    "for rdd_key in list_rdds():\n",
    "    print(\"rdd_key =\", rdd_key)\n",
    "    set_rdds.add(globals()[rdd_key])\n",
    "\n",
    "for rdd in set_rdds:\n",
    "    print (rdd.name(), \", my Num Partitions=\", rdd.getNumPartitions(), sep='')\n",
    "    # print(type(globals()[k]))\n",
    "    # rdd = globals()[rdd_key]\n",
    "    if rdd.is_cached:\n",
    "        print ('  I am persisted')\n",
    "    else:\n",
    "        print ('  I am not persisted')\n",
    "    # del rdd\n",
    "    #     # globals()[k].unpersist()\n",
    "    #     # globals()[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c0de1e-7237-433f-9aca-414eabab0a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark import RDD\n",
    "\n",
    "# def list_rdds():\n",
    "#     return [k for (k, v) in globals().items() if isinstance(v, RDD)]\n",
    "# rdds = set()\n",
    "\n",
    "# for k in list_rdds():\n",
    "#     rdds.add(globals()[k])\n",
    "\n",
    "# for rdd in rdds:\n",
    "#     # print(globals()[k].name())\n",
    "#     # print(type(globals()[k]))\n",
    "#     if rdd.is_cached:\n",
    "#         print (rdd, '-  persisted')\n",
    "#     else:\n",
    "#         print (rdd, '-  not persisted')\n",
    "#     #     # globals()[k].unpersist()\n",
    "#     #     # globals()[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e244ed93-1a7d-452c-b8c2-b255d6656af3",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37dc8a7-69ab-4b0d-a751-c272f59b8681",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
